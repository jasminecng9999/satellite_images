# Image model classifier
1.Download jupyter 

I used the “SAT-4 Airborne Dataset” provided by the National Agriculture Imagery Program and compiled by the Bay Area Environmental Research Institute/NASA Ames Research Center--which can be found through this link: http://csc.lsu.edu/~saikat/deepsat/.The training set and test set are both in MATLAB v5 mat-file format. The variable text x contains the training images. It is a 28x28x4x400000 array of uint8 variables (that is, integers between 0 and 255). The last dimension encodes the index of the image. The first and second dimensions encode the row and column, respectively, of the pixel. The third dimension describes the channel: index 0 is red, 1 is green, 2 is blue, and 3 is NIR.The variable train y provides the labels for the training set. It is a 4x400000 array of bits, done by one-hot encoding. 

I coded and optimized three types of classifers: SVM, Logistic Regression using PyTorch, and Gradient Descent. These models classified satellite images into one of four labels: “barren land”, “trees”, “grassland”, or “none”. I trained and validated each optimized model to pick which model performed the best on the validation dataset. This process was done in the train.ipynb file. Picking SVM as my best performance model and training SVM, I saved the classifier and its parameters to model.dat using the pickle module. The model.dat file can be generated by running the train.ipynb file. The satellite.ipynb reads the file from model.dat without retraining to compute its classification decisions on the test set. Finally, the last file is a final report to evaluate the performance of my classifiers as well as documenting my reasonings and thought process. 

